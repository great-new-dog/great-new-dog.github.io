<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习实践——优化问题求解</title>
      <link href="/post/27506d5c.html"/>
      <url>/post/27506d5c.html</url>
      
        <content type="html"><![CDATA[<p>使用<code>pytorch</code>可以很方便地求解优化问题。关键在于构建目标函数，确定优化变量，选择合适的优化器以及设置合理的学习率。</p><p>下面使用求解himmelblau函数极小值点作为例子来演示如何使用<code>pytorch</code>求解优化问题。</p><h3 id="构建目标函数"><a href="#构建目标函数" class="headerlink" title="构建目标函数"></a>构建目标函数</h3><p>求解himmelblau函数的极小值点，就是使得himmelblau函数的值最小，因此直接将himmelblau函数作为目标函数即可。所构建目标函数公式如下：</p><script type="math/tex; mode=display">f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2</script><h3 id="确定优化变量"><a href="#确定优化变量" class="headerlink" title="确定优化变量"></a>确定优化变量</h3><p>优化变量即需要求解的极小值点，在这里就是<code>(x,y)</code>。</p><h3 id="选择优化器"><a href="#选择优化器" class="headerlink" title="选择优化器"></a>选择优化器</h3><p><code>pytorch</code>提供了多种优化器，如<code>SGD</code>、<code>Adam</code>等，这里可以选择<code>Adam</code>优化器。</p><h3 id="设置学习率"><a href="#设置学习率" class="headerlink" title="设置学习率"></a>设置学习率</h3><p>学习率是优化器的一个重要参数，对于优化求解的效果有很大影响。</p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p>下面是使用<code>pytorch</code>求解himmelblau函数极小值点的完整代码示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">himmelblau</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Himmelblau function, a common test function for optimization algorithms.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    f(x) = (x[0]**2 + x[1] - 11)**2 + (x[0] + x[1]**2 - 7)**2 </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>]**<span class="number">2</span> + x[<span class="number">1</span>] - <span class="number">11</span>)**<span class="number">2</span> + (x[<span class="number">0</span>] + x[<span class="number">1</span>]**<span class="number">2</span> - <span class="number">7</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">x = torch.tensor([-<span class="number">4.0</span>,<span class="number">2.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">opt = torch.optim.Adam([x], lr=<span class="number">1e-3</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10001</span>):</span><br><span class="line">    pred = himmelblau(x)</span><br><span class="line">    opt.zero_grad()</span><br><span class="line">    pred.backward()</span><br><span class="line">    opt.step()</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Step <span class="subst">&#123;i&#125;</span>, x: <span class="subst">&#123;x.detach().numpy()&#125;</span>, f(x): <span class="subst">&#123;pred.item()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>需要注意的是，在上述例子中，himmelblau函数有四个极小值点，不同变量初始值会导致最终求解的极小值点不同，因此在实际应用中需要根据具体问题进行具体分析和调整。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 优化求解 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的合并与分割</title>
      <link href="/post/70aa01c1.html"/>
      <url>/post/70aa01c1.html</url>
      
        <content type="html"><![CDATA[<p>对张量进行合并和分割也是常见的操作，以下是一些常用方法。</p><h3 id="合并操作"><a href="#合并操作" class="headerlink" title="合并操作"></a>合并操作</h3><p>使用<code>torch.cat</code>可以将多个张量沿指定维度进行合并。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">c = torch.cat([a,b],dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br></pre></td></tr></table></figure></p><p>另一个常用的合并方法是<code>torch.stack</code>，但是会生成一个新的维度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">c = torch.stack([a,b],dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br></pre></td></tr></table></figure></p><h3 id="分割操作"><a href="#分割操作" class="headerlink" title="分割操作"></a>分割操作</h3><p>使用<code>split</code>可以将一个张量沿指定维度分割成多个子张量,需要指定分割后子张量的长度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">b1,b2,b3 = a.split([<span class="number">2</span>,<span class="number">1</span>，<span class="number">3</span>], dim=<span class="number">0</span>)  </span><br><span class="line"><span class="built_in">print</span>(b1.shape)</span><br><span class="line"><span class="built_in">print</span>(b2.shape)</span><br><span class="line"><span class="built_in">print</span>(b3.shape)</span><br></pre></td></tr></table></figure></p><p>使用<code>torch.chunk</code>可以将一个张量沿指定维度分割成指定数量的子张量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">b1,b2,b3 = a.chunk(<span class="number">3</span>, dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(b2.shape)</span><br><span class="line"><span class="built_in">print</span>(b3.shape)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的数学运算</title>
      <link href="/post/9c352926.html"/>
      <url>/post/9c352926.html</url>
      
        <content type="html"><![CDATA[<h3 id="基础运算"><a href="#基础运算" class="headerlink" title="基础运算"></a>基础运算</h3><p>张量可以进行基本的数学运算，加减乘除等，需要注意的是，运算是对张量中的每一各元素进行，进行运算的张量需要具有相同的形状，或者可以通过广播机制满足条件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">c = a + b <span class="comment"># c = torch.add(a,b)</span></span><br><span class="line">d = a - b <span class="comment"># d = torch.sub(a,b)</span></span><br><span class="line">e = a * b <span class="comment"># e = torch.mul(a,b)</span></span><br><span class="line">f = a / b <span class="comment"># f = torch.div(a,b)</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h3><p>对于二维张量，可以进行矩阵乘法运算，但需要满足矩阵乘法的条件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">c = a @ b  <span class="comment"># c = torch.matmul(a, b) </span></span><br></pre></td></tr></table></figure><h3 id="幂乘，指数和对数"><a href="#幂乘，指数和对数" class="headerlink" title="幂乘，指数和对数"></a>幂乘，指数和对数</h3><p>张量可以进行幂乘、指数和对数运算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = a ** <span class="number">2</span>  <span class="comment"># 幂乘      </span></span><br><span class="line">c = torch.exp(a)  <span class="comment"># 指数</span></span><br><span class="line">d = torch.log(a)  <span class="comment"># 对数</span></span><br></pre></td></tr></table></figure></p><h3 id="统计运算"><a href="#统计运算" class="headerlink" title="统计运算"></a>统计运算</h3><p>张量可以进行统计运算，如求和、均值、最大值、最小值等。同时，统计运算还可以指定维度进行计算,如果不指定维度，则默认对所有元素进行统计。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])          </span><br><span class="line">b = torch.<span class="built_in">sum</span>(a,dim=<span class="number">0</span>)  <span class="comment"># 求和</span></span><br><span class="line">c = torch.mean(a,dim=<span class="number">0</span>)  <span class="comment"># 均值</span></span><br><span class="line">value, index = torch.<span class="built_in">max</span>(a,dim=<span class="number">1</span>)  <span class="comment"># 最大值</span></span><br><span class="line">value, index = torch.<span class="built_in">min</span>(a,dim=<span class="number">1</span>)  <span class="comment"># 最小值</span></span><br><span class="line">f = torch.std(a)  <span class="comment"># 标准差</span></span><br><span class="line">g = torch.var(a)  <span class="comment"># 方差</span></span><br></pre></td></tr></table></figure></p><h3 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h3><p>张量可以进行逻辑运算，如与、或、非等。逻辑运算返回布尔类型的张量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">c = a &gt; b  <span class="comment"># 大于 </span></span><br><span class="line">d = a &lt; b  <span class="comment"># 小于</span></span><br><span class="line">e = a == b  <span class="comment"># 等于</span></span><br><span class="line">f = a != b  <span class="comment"># 不等于</span></span><br><span class="line">g = a &amp; b  <span class="comment"># torch.logical_and(a, b)  # 与</span></span><br><span class="line">h = a | b  <span class="comment"># torch.logical_or(a, b)  # 或</span></span><br><span class="line">i = ~a     <span class="comment"># torch.logical_not(a)  # 非</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的索引和切片</title>
      <link href="/post/5521720d.html"/>
      <url>/post/5521720d.html</url>
      
        <content type="html"><![CDATA[<p>索引用来访问张量中的特定元素或者子集。对张量进行索引和切片是处理多维数据的重要操作，以下是一些常见的索引和切片方法。</p><h3 id="基本索引"><a href="#基本索引" class="headerlink" title="基本索引"></a>基本索引</h3><p>最简单的索引方式是使用整数对张量进行索引。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">16</span>,<span class="number">16</span>)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>,<span class="number">0</span>].shape)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure></p><h3 id="切片索引"><a href="#切片索引" class="headerlink" title="切片索引"></a>切片索引</h3><p>切片索引更加灵活地选取张量中的部分数据，使用整数和冒号的多种组合来实现不同的切片。</p><h4 id="选取前-后n个"><a href="#选取前-后n个" class="headerlink" title="选取前/后n个"></a>选取前/后n个</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">16</span>,<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个维度选取前两个</span></span><br><span class="line"><span class="built_in">print</span>(a[:<span class="number">2</span>].shape)</span><br><span class="line"><span class="comment"># 第二个维度选取后两个</span></span><br><span class="line"><span class="built_in">print</span>(a[:,-<span class="number">2</span>:].shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="选取特定范围"><a href="#选取特定范围" class="headerlink" title="选取特定范围"></a>选取特定范围</h4><p>选取特定范围的元素可以使用整数加冒号加整数的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">16</span>,<span class="number">16</span>)</span><br><span class="line"><span class="comment"># 第一个维度选取第1到第3个</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">1</span>:<span class="number">3</span>].shape)</span><br></pre></td></tr></table></figure><h4 id="按步长选取"><a href="#按步长选取" class="headerlink" title="按步长选取"></a>按步长选取</h4><p>切片时可以指定步长，使用整数加冒号加整数加冒号加整数的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">16</span>,<span class="number">16</span>)</span><br><span class="line"><span class="comment"># 第三个维度选取第1到第3个，步长为2</span></span><br><span class="line"><span class="built_in">print</span>(a[:,:,<span class="number">0</span>:<span class="number">10</span>:<span class="number">2</span>].shape)</span><br></pre></td></tr></table></figure><h4 id="任意维度"><a href="#任意维度" class="headerlink" title="任意维度"></a>任意维度</h4><p>对于维度比较多的张量，可以配合<code>...</code>来选取任意维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">16</span>,<span class="number">16</span>)</span><br><span class="line"><span class="comment"># 选取最后一个维度的后两个</span></span><br><span class="line"><span class="built_in">print</span>(a[..., -<span class="number">2</span>:].shape)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的维度变换</title>
      <link href="/post/9d3c0312.html"/>
      <url>/post/9d3c0312.html</url>
      
        <content type="html"><![CDATA[<h3 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h3><p>张量的维度变换是指对张量的形状进行调整，以满足特定的计算需求。以下是一些常见的维度变换操作。</p><h3 id="view或reshape"><a href="#view或reshape" class="headerlink" title="view或reshape"></a>view或reshape</h3><p><code>view</code>或<code>reshape</code>操作用于改变张量的形状，但不改变其数据。使用的前提是张量的总元素数量保持不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = a.view(<span class="number">4</span>,<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="squeeze和unsqueeze"><a href="#squeeze和unsqueeze" class="headerlink" title="squeeze和unsqueeze"></a>squeeze和unsqueeze</h3><p><code>squeeze</code>操作用于去除张量中维度为1的维度，而<code>unsqueeze</code>操作用于在指定位置添加一个维度为1的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">b = a.unsqueeze(<span class="number">0</span>)</span><br><span class="line">c = b.unsqueeze(-<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">d = c.squeeze(<span class="number">0</span>)</span><br><span class="line">e = c.squeeze()</span><br></pre></td></tr></table></figure><h3 id="expand和repeat"><a href="#expand和repeat" class="headerlink" title="expand和repeat"></a>expand和repeat</h3><p><code>expand</code>操作用于扩展张量的维度，而<code>repeat</code>用于重复张量的元素。注意，<code>expand</code>只能扩展大小为1的维度，而<code>repeat</code>是将维度上的数据进行复制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>) </span><br><span class="line">b = a.expand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)  <span class="comment"># 扩展到2x3x4</span></span><br><span class="line">c = a.repeat(<span class="number">2</span>,<span class="number">2</span>)  <span class="comment"># 重复2x</span></span><br><span class="line"><span class="built_in">print</span>(b.shape)  <span class="comment"># 输出: torch.Size([2, 3, 4])</span></span><br><span class="line"><span class="built_in">print</span>(c.shape)  <span class="comment"># 输出: torch.Size([2, 3, 4])</span></span><br></pre></td></tr></table></figure><h3 id="transpose和permute"><a href="#transpose和permute" class="headerlink" title="transpose和permute"></a>transpose和permute</h3><p><code>transpose</code>用于交换张量的两个维度，而<code>permute</code>用于重新排列张量的所有维度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = a.transpose(<span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># 交换第0维和第1维</span></span><br><span class="line">c = a.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># 重新排列维度</span></span><br><span class="line"><span class="built_in">print</span>(b.shape)  <span class="comment"># 输出: torch.Size([3, 2, 4])</span></span><br><span class="line"><span class="built_in">print</span>(c.shape)  <span class="comment"># 输出: torch.Size([4, 2, 3])</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的创建</title>
      <link href="/post/68634a11.html"/>
      <url>/post/68634a11.html</url>
      
        <content type="html"><![CDATA[<h3 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h3><p><code>Tensor</code>的创建可以通过多种方式完成，以下是一些常用的方法。</p><h4 id="从numpy数组创建"><a href="#从numpy数组创建" class="headerlink" title="从numpy数组创建"></a>从<code>numpy</code>数组创建</h4><p>使用<code>torch.from_numpy()</code>函数将已经创建好的<code>numpy</code>数组转换为<code>Tensor</code>。需要注意的是，两者共享内存，对其中一个的修改会影响到另一个。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = torch.from_numpy(a)</span><br></pre></td></tr></table></figure><h4 id="从list创建"><a href="#从list创建" class="headerlink" title="从list创建"></a>从<code>list</code>创建</h4><p>使用<code>torch.tensor()</code>函数可以根据<code>list</code>来创建<code>Tensor</code>。这种方法适用于小规模的数据，并且会对数据进行拷贝，两者之间不会互相影响。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = torch.tensor(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h4 id="非初始化创建"><a href="#非初始化创建" class="headerlink" title="非初始化创建"></a>非初始化创建</h4><p>使用<code>torch.empty()</code>,<code>torch.FloatTensor()</code>等可以创建未初始化但已分配内存的<code>Tensor</code>。<code>set_default_dtype()</code>函数可以设置默认的<code>Tensor</code>类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.empty(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = torch.FloatTensor(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">set_default_dtype(torch.float64)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="随机初始化创建"><a href="#随机初始化创建" class="headerlink" title="随机初始化创建"></a>随机初始化创建</h4><p>使用<code>torch.rand()``torch.randint()</code>和<code>torch.randn()</code>可以创建随机初始化的<code>Tensor</code>。注意，<code>torch.randint()</code>输入参数为最小值、最大值和形状，且区间是左闭右开的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">3</span>, <span class="number">4</span>)        </span><br><span class="line">b = torch.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">3</span>, <span class="number">4</span>))  </span><br><span class="line">c = torch.randn(<span class="number">3</span>, <span class="number">4</span>)      </span><br></pre></td></tr></table></figure></p><h4 id="特定数字填充创建"><a href="#特定数字填充创建" class="headerlink" title="特定数字填充创建"></a>特定数字填充创建</h4><p>使用<code>torch.full()</code>可以创建一个指定形状和填充值的<code>Tensor</code>。更特别地，<code>torch.ones()</code>和<code>torch.zeros()</code>可以创建全1或全0的<code>Tensor</code>。<code>torch.eye()</code>可以创建单位矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.full((<span class="number">3</span>, <span class="number">4</span>), <span class="number">5</span>)</span><br><span class="line">b = torch.ones(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">c = torch.zeros(<span class="number">3</span>, <span class="number">4</span>)       </span><br><span class="line">d = torch.eye(<span class="number">3</span>, <span class="number">4</span>)          </span><br></pre></td></tr></table></figure><h4 id="等分形式创建"><a href="#等分形式创建" class="headerlink" title="等分形式创建"></a>等分形式创建</h4><p>使用<code>torch.linspace()</code>和<code>torch.arange()</code>可以创建等分的<code>Tensor</code>。<code>torch.linspace()</code>用于创建指定范围内的等间隔数值，而<code>torch.arange()</code>用于创建指定步长的数值序列。注意，前者区间是左闭右闭的，而后者是左闭右开的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.linspace(<span class="number">0</span>, <span class="number">1</span>, steps=<span class="number">5</span>)  <span class="comment"># 从0到1，包含5个等间隔的数值</span></span><br><span class="line">b = torch.arange(<span class="number">0</span>, <span class="number">10</span>, step=<span class="number">2</span>)  <span class="comment"># 从0到10，步长为2</span></span><br></pre></td></tr></table></figure><h4 id="随机索引创建"><a href="#随机索引创建" class="headerlink" title="随机索引创建"></a>随机索引创建</h4><p>使用<code>torch.randperm()</code>可以创建一个随机排列的索引序列，常用于数据的随机抽样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randperm(<span class="number">10</span>)  <span class="comment"># 创建一个0到9的随机排列</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch张量基础用法——张量的类型和维度</title>
      <link href="/post/f7d6a20d.html"/>
      <url>/post/f7d6a20d.html</url>
      
        <content type="html"><![CDATA[<h3 id="张量的类型"><a href="#张量的类型" class="headerlink" title="张量的类型"></a>张量的类型</h3><p>在<code>pytorch</code>当中，所有的数据处理计算都是基于张量，即<code>tensor</code>来完成的。而<code>tensor</code>的类型主要有以下这几种。</p><div class="table-container"><table><thead><tr><th>data type</th><th>dtype</th><th>cpu tensor</th><th>gpu tensor</th></tr></thead><tbody><tr><td>float32</td><td>torch.float32</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>float64</td><td>torch.float64</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr><tr><td>int32</td><td>torch.int32</td><td>torch.IntTensor</td><td>torch.cuda.IntTensor</td></tr><tr><td>int64</td><td>torch.int64</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>uint8</td><td>torch.uint8</td><td>torch.ByteTensor</td><td>torch.cuda.ByteTensor</td></tr><tr><td>bool</td><td>torch.bool</td><td>torch.BoolTensor</td><td>torch.cuda.BoolTensor</td></tr></tbody></table></div><p>需要注意的是，cpu和gpu的张量类型是不同的。类型检查可以使用函数<code>isinstance()</code> 或成员函数<code>type()</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">type</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">isinstance</span>(a, torch.FloatTensor))</span><br></pre></td></tr></table></figure></p><h3 id="标量"><a href="#标量" class="headerlink" title="标量"></a>标量</h3><p>标量是一个0维的张量，往往是对应于机器学习中损失函数的值（loss）。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scalar = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line"><span class="built_in">print</span>(scalar)</span><br></pre></td></tr></table></figure></p><h3 id="一维张量"><a href="#一维张量" class="headerlink" title="一维张量"></a>一维张量</h3><p>一维张量是一个向量，通常对应于机器学习中的标签向量(label)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ylabel = torch.tensor([<span class="number">1.0</span>, <span class="number">2.0</span>])</span><br></pre></td></tr></table></figure></p><h3 id="二维张量"><a href="#二维张量" class="headerlink" title="二维张量"></a>二维张量</h3><p>二维张量是一个矩阵，通常对应于机器学习中带<code>batch</code>的线性输入数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></p><h3 id="三维张量"><a href="#三维张量" class="headerlink" title="三维张量"></a>三维张量</h3><p>三维张量通常被用于RNN网络中，对应（word， sentence， feature）。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p><h3 id="四维张量"><a href="#四维张量" class="headerlink" title="四维张量"></a>四维张量</h3><p>四维张量通常用于卷积神经网络CNN中，对应(batch, channel, height, width)。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure></p><h3 id="张量维度查看"><a href="#张量维度查看" class="headerlink" title="张量维度查看"></a>张量维度查看</h3><p>张量的维度可以使用<code>shape</code>属性来查看，也可以使用<code>size()</code>成员函数来查看，或者使用<code>dim()</code>成员函数来查看，该函数直接返回一个整数。对于张量中的元素个数，使用<code>numel()</code>成员函数查看。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(a.shape) </span><br><span class="line"><span class="built_in">print</span>(a.size())</span><br><span class="line"><span class="built_in">print</span>(a.dim())</span><br><span class="line"><span class="built_in">print</span>(a.numel())</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四足机器运动控制系列———插值与规划</title>
      <link href="/post/f5ef82c0.html"/>
      <url>/post/f5ef82c0.html</url>
      
        <content type="html"><![CDATA[<h3 id="插值与规划"><a href="#插值与规划" class="headerlink" title="插值与规划"></a>插值与规划</h3><p>在足式机器人控制当中，一个很重要的问题是对足端轨迹进行规划。一个合理的足端轨迹应该保持位置和速度在时间上的连续，在实际应用过程中，当规划好一段足端轨迹后，则需要根据规划好的该曲线进行插值，从而得到一系列的足底坐标点，作为控制器的输入参数进行控制求解。</p><p>常用的插值方法包括有三次样条曲线插值以及贝塞尔曲线插值。</p><h4 id="三次样条曲线插值"><a href="#三次样条曲线插值" class="headerlink" title="三次样条曲线插值"></a>三次样条曲线插值</h4><p>已知条件：</p><ol><li>起始点$x_0$处函数值$y_0$</li><li>终止点$x_f$处函数值$y_f$</li><li>起始点处一阶导数为$v_0$</li><li>终止点处一阶导数为$v_f$</li></ol><p>引入参数$t$，且$t \in (0,1)$<br>易得变量$x$的插值方程如下：</p><script type="math/tex; mode=display">x(t) = x_0 + (x_f - x_0) t\tag{9}</script><p>设函数值$y$的插值方程为：<br>设该三次样条插值函数为：</p><script type="math/tex; mode=display">f(t) = a_0 + a_1 t + a_2 t^2 + a_3 t^3 \tag{1}</script><p>其中 $a_i, i= 0, 1, 2, 3$为待定系数。</p><p>易得其导数方程为：</p><script type="math/tex; mode=display">f'(t) = a_1 + 2a_2*t + 3a_3*t^2 \tag{2}</script><p>将条件1带入$(1)$可得：</p><script type="math/tex; mode=display">f(t=0) = a_0 = y_0 \tag{3}</script><p>将条件2带入函数$(1)$可得：</p><script type="math/tex; mode=display">f(t=1) = a_0 + a_1 + a_2 + a_3 = y_f \tag{4}</script><p>将条件3带入$(2)$可得：</p><script type="math/tex; mode=display">f'(t=0) = a_1 = v_0 \tag{5}</script><p>将条件4带入$(2)$可得：</p><script type="math/tex; mode=display">f'(t=1) = a_1 + 2a_2 + 3a_3 = v_f \tag{6}</script><p>求解上述方程，可以得到：</p><script type="math/tex; mode=display">\begin{aligned}a_0 &= y_0 \\a_1 &= v_0 \\a_2 &=  3(y_f-y_0) - 2v_0 - v_f\\a_3 &= v_0 + v_f - 2(y_f - y_0)\end{aligned}\tag{8}</script><h4 id="贝塞尔曲线插值"><a href="#贝塞尔曲线插值" class="headerlink" title="贝塞尔曲线插值"></a>贝塞尔曲线插值</h4><p>三次贝塞尔插值需要四个控制点，一般把起始点作为第一和第二个控制点，而把终止点作为第三和第四个控制点。</p><p>若已知条件为：</p><ol><li>起始点$x_0$处函数值$y_0$</li><li>终止点$x_f$处函数值$y_f$</li><li>起始点处一阶导数为0</li><li>终止点处一阶导数为0</li></ol><p>引入参数$t$，且$t \in (0,1)$<br>则可以得到插值方程如下：</p><script type="math/tex; mode=display">x(t) = x_0 + (x_f - x_0) t\tag{9}</script><script type="math/tex; mode=display">y(t) = (1-t)^3*y_0 + 3(1-t)^2t*y_0 + 3(1-t)t^2*y_f + t^3*y_f \\ = y_0 + (3-2t)t^2*(y_f-y_0) \tag{10}</script><h3 id="程序验证"><a href="#程序验证" class="headerlink" title="程序验证"></a>程序验证</h3><p>参考<a href="https://github.com/great-new-dog/quadruped_control/tree/master/swing_leg_trajectory_plan">quadruped_control仓库</a><br>上述程序中使用了mujoco仿真器，对宇树Go1进行了单腿轨迹规划的仿真。<br>仿真结果如下所示：</p><p>动态图：</p><p><img src="../imgs/ani.gif" alt="alt text"></p><p>足底轨迹：<br><img src="../imgs/leg_traj.png" alt="alt text"></p><p>关节位置：<br><img src="../imgs/joint_ang.png" alt="alt text"></p><p>关节速度：<br><img src="../imgs/joint_vel.png" alt="alt text"></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 足式机器人 </tag>
            
            <tag> 插值 </tag>
            
            <tag> 三次样条曲线 </tag>
            
            <tag> 贝塞尔曲线 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux系统下定时器设计</title>
      <link href="/post/f8431890.html"/>
      <url>/post/f8431890.html</url>
      
        <content type="html"><![CDATA[<h3 id="linux-系统下定时器设计及实现"><a href="#linux-系统下定时器设计及实现" class="headerlink" title="linux 系统下定时器设计及实现"></a>linux 系统下定时器设计及实现</h3><p>在机器人控制系统中，实时性要求较高，控制任务需要通过定时器来精确控制运行频率。</p><p>而在linux系统下，timefd提供了一种基于文件描述符的定时器接口，允许用户程序通过文件描述符的可读事件来接收定时器的到期通知，且精度较高。</p><p>而为了减少在程序中不断去访问文件的可读事件，可以借用epoll的事件通知机制，无需轮询访问。</p><p>因此，结合timerfd和epoll，可以在linux系统下实现一个高效且精确的定时器，满足实时控制的需要。进一步，为了方便使用，可以使用C++进行类的封装。</p><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><h4 id="类的定义"><a href="#类的定义" class="headerlink" title="类的定义"></a>类的定义</h4><p>主要定义三个类，首先是实现定时器功能的<code>Timer</code>类，其次是继承于<code>Timer</code>类的单例<code>PrintTimer</code>类，用来打印所有定时器的信息，最后是用来管理所有定时器的<code>TimerManager</code>类。</p><h4 id="详细说明"><a href="#详细说明" class="headerlink" title="详细说明"></a>详细说明</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Timer</span>(TimerManager* timerManager, <span class="type">uint16_t</span> period, std::string name, std::function&lt;<span class="built_in">void</span>()&gt; callback);</span><br><span class="line">    ~<span class="built_in">Timer</span>();</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">init</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">start</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">stop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">printStatus</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">std::string <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> _epoll_fd;</span><br><span class="line">    <span class="type">int</span> _timer_fd;</span><br><span class="line">    <span class="type">uint16_t</span> _period;</span><br><span class="line">    std::string _name;</span><br><span class="line">    std::function&lt;<span class="type">void</span>()&gt; _callback;</span><br><span class="line">    std::thread _thread;</span><br><span class="line">    std::atomic&lt;<span class="type">bool</span>&gt; _running;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> _averageRuntime = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> _lastRuntime = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> _maxRuntime = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>如上所示，在<code>Timer</code>类中主要有<code>init</code>，<code>start</code>,<code>stop</code>,<code>printStatus</code>等成员函数，分别实现初始化，开始定时任务，结束定时任务以及打印定时任务信息的功能。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TimerManager</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">TimerManager</span>() = <span class="keyword">default</span>;</span><br><span class="line">    ~<span class="built_in">TimerManager</span>() &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">addTask</span><span class="params">(Timer* timer)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">printStatus</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">stopAll</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::unordered_map&lt;std::string, std::unique_ptr&lt;Timer&gt;&gt; _timers;</span><br><span class="line">    std::mutex _mutex;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>对于<code>TimerManager</code>类，主要是<code>addTask</code>,<code>printStatus</code>两个成员函数，用来添加定时任务，打印定时任务的状态。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrintTimer</span> : <span class="keyword">public</span> Timer</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">PrintTimer</span>(TimerManager* timerManager, <span class="type">uint16_t</span> period) </span><br><span class="line">        : <span class="built_in">Timer</span>(timerManager, period, <span class="string">&quot;print-task&quot;</span>, <span class="literal">nullptr</span>), _timerManager(timerManager) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">run</span><span class="params">()</span> <span class="keyword">override</span></span>;</span><br><span class="line">    TimerManager* _timerManager;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>PrintTimer</code>类相对比较简单，主要实现了定时调用<code>TimerManager</code>的<code>printStatus</code>功能。</p><h3 id="简单例子"><a href="#简单例子" class="headerlink" title="简单例子"></a>简单例子</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">printfun1</span><span class="params">(<span class="type">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="comment">// std::cout &lt;&lt; &quot; hhhh &quot; &lt;&lt; std::endl;</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">10</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printfun2</span><span class="params">(<span class="type">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="comment">// std::cout &lt;&lt; &quot; zzzz &quot; &lt;&lt; std::endl;</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">10</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    TimerManager timerManager;</span><br><span class="line"></span><br><span class="line">    <span class="function">Timer <span class="title">timer_test1</span><span class="params">(&amp;timerManager, <span class="number">1000</span>, <span class="string">&quot;test1&quot;</span>, printfun1)</span></span>;</span><br><span class="line">    <span class="function">Timer <span class="title">timer_test2</span><span class="params">(&amp;timerManager, <span class="number">2000</span>, <span class="string">&quot;test2&quot;</span>, printfun2)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">PrintTimer <span class="title">printTimer</span><span class="params">(&amp;timerManager, <span class="number">4000</span>)</span></span>;</span><br><span class="line">    printTimer.<span class="built_in">start</span>();</span><br><span class="line">    timer_test<span class="number">1.</span><span class="built_in">start</span>();</span><br><span class="line">    timer_test<span class="number">2.</span><span class="built_in">start</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">        std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述程序简单建立了两个实时任务，程序运行的效果如下所示：<br><img src="../imgs/timer_result.png" alt="timer result"><br>程序定时打印了两个实时任务的信息，包括平均运行时间，上一次运行时间，最大运行时间和运行周期等信息。</p><h3 id="程序源码"><a href="#程序源码" class="headerlink" title="程序源码"></a>程序源码</h3><p>程序源码见<a href="https://github.com/great-new-dog/Timer">定时器</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 定时器 </tag>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四足机器运动控制系列————单腿运动学</title>
      <link href="/post/792d5bbe.html"/>
      <url>/post/792d5bbe.html</url>
      
        <content type="html"><![CDATA[<h3 id="正运动学"><a href="#正运动学" class="headerlink" title="正运动学"></a>正运动学</h3><p>正运动学(forward kinematics)是指根据关节的角度求解机器人各关节以及末端的位姿。对于四足机器人来说，问题简化为通过三个关节的角度计算足底的位置。</p><h4 id="旋转矩阵"><a href="#旋转矩阵" class="headerlink" title="旋转矩阵"></a>旋转矩阵</h4><p>定义绕$x,y,z$轴旋转的旋转矩阵分别为$R_x, R_y, R_z$，则表达式为：</p><script type="math/tex; mode=display">R_x(\theta) = \begin{bmatrix}    1 & 0 & 0 \\    0 & cos(\theta) & -sin(\theta) \\    0 & sin(\theta) & cos(\theta) \\\end{bmatrix}</script><script type="math/tex; mode=display">R_y(\theta) = \begin{bmatrix}    cos(\theta) & 0 & sin(\theta) \\    0 & 1 & 0 \\    0 & -sin(\theta) & cos(\theta) \\\end{bmatrix}</script><script type="math/tex; mode=display">R_z(\theta) = \begin{bmatrix}    cos(\theta) & -sin(\theta) & 0 \\    sin(\theta) & cos(\theta) & 0 \\    0 & 0 & 1 \\\end{bmatrix}</script><h4 id="单腿正运动学计算"><a href="#单腿正运动学计算" class="headerlink" title="单腿正运动学计算"></a>单腿正运动学计算</h4><p>首先，已知量有：</p><ul><li>侧摆关节、髋关节和膝关节的旋转角度 <script type="math/tex; mode=display">[\theta_{1}, \theta_{2}, \theta_{3}]</script></li><li>侧摆连杆、大腿连杆和小腿连杆的长度 <script type="math/tex; mode=display">[l_{1}, l_{2}, l_{3}]</script></li><li>侧摆关节在身体坐标系下的位置 <script type="math/tex; mode=display">[l_x, l_y, 0]</script></li></ul><p>然后，先求解在髋关节坐标系下的足底位置，公式如下：</p><script type="math/tex; mode=display">p_{f}' = \begin{bmatrix}    0 \\    0 \\    -l_{2}\end{bmatrix} + \begin{bmatrix}    cos(\theta_{3}) & 0 & sin(\theta_{3}) \\    0 & 1 & 0 \\    -sin(\theta_{3}) & 0 & cos(\theta_{3}) \end{bmatrix} * \begin{bmatrix}    0 \\    0 \\    -l_{3}\end{bmatrix}</script><p>解得</p><script type="math/tex; mode=display">p_{f}' = \begin{bmatrix}    -l_{3}sin(\theta_{3}) \\    0 \\    -l_{2} - l_{3}cos(\theta_{3})\end{bmatrix}</script><p>再求解在侧摆关节坐标系下的足底位置，公式如下：</p><script type="math/tex; mode=display">p_{f}'' = \begin{bmatrix}    0 \\    \epsilon l_{1} \\    0\end{bmatrix} + \begin{bmatrix}    cos(\theta_{2}) & 0 & sin(\theta_{2}) \\    0 & 1 & 0 \\    -sin(\theta_{2}) & 0 & cos(\theta_{2}) \end{bmatrix} * p_{f}'</script><p>可解得</p><script type="math/tex; mode=display">p_{f}'' = \begin{bmatrix}    -l_{2}sin(\theta_{2})-l_{3}sin(\theta_{2} + \theta_{3}) \\    \epsilon l_{1} \\    -l_{2}cos(\theta_{2}) - l_{3}cos(\theta_{2} + \theta_{3})\end{bmatrix}</script><p>最后，求解在身体坐标系下的足底位置，公式如下：</p><script type="math/tex; mode=display">p_{f}^{b} = \begin{bmatrix}    \delta *l_x \\    \epsilon *l_y \\    0\end{bmatrix} + \begin{bmatrix}    1 & 0 & 0 \\    0 & cos(\theta_{1}) & -sin(\theta_{1}) \\    0 & sin(\theta_{1}) & cos(\theta_{1}) \end{bmatrix} * p_{f}''</script><p>最终得到：</p><script type="math/tex; mode=display">p_{f}^{b} = \begin{bmatrix}    \delta *l_x - l_{2}sin(\theta_{2}) - l_3sin(\theta_2 + \theta_3) \\    \epsilon *l_y + \epsilon * l_{1}cos(\theta_1) + l_2sin(\theta_1)cos(\theta_2) + l_3sin(\theta_1)cos(\theta_2+\theta_3) \\    \epsilon*l_{1}sin(\theta_1) - l_2cos(\theta_1)cos(\theta_2)-l_3cos(\theta_1)cos(\theta_2+\theta_3)\end{bmatrix}</script><p>在上述公式中，</p><script type="math/tex; mode=display">\delta = \begin{cases}    1, & \text{如果为前腿}\\    -1, & \text{如果为后腿}\end{cases}</script><script type="math/tex; mode=display">\epsilon = \begin{cases}    1, & \text{如果为左腿}\\    -1, & \text{如果为右腿}\end{cases}</script><h3 id="逆运动学"><a href="#逆运动学" class="headerlink" title="逆运动学"></a>逆运动学</h3><p>逆运动学则与正运动学相反，是在已知末端位姿的条件下，求解各个关节的角度。对于四足机器人来说，是根据足底位置来求解三个关节的角度。</p><p>求解逆运动学更一般的方法是通过数值方法，但由于四足机器人的逆运动学问题较为简单，可以直接通过解析法求解。</p><h4 id="解析法"><a href="#解析法" class="headerlink" title="解析法"></a>解析法</h4><p>若已知在侧摆关节坐标系下的足底位置</p><script type="math/tex; mode=display">[p_x, p_y, p_z]^T</script><p>则各个关节的角度计算公式如下：<br><img src="../imgs/theta_1.png" alt="theta_1"></p><p>首先计算侧摆关节</p><script type="math/tex; mode=display">\begin{bmatrix}    p_y \\    p_z\end{bmatrix} = \begin{bmatrix}    cos(\theta_1) & -sin(\theta_1) \\    sin(\theta_1) & cos(\theta_1) \\\end{bmatrix}\begin{bmatrix}    l_1 \\    -L\end{bmatrix}</script><p>其中 </p><script type="math/tex; mode=display">L = \sqrt{p_y^2 + p_z^2 - l_1^2}</script><p>由此可得：</p><script type="math/tex; mode=display">\theta_1 = arctan(\frac{p_zl_1+p_yL}{p_yl_1-p_zL})</script><p><img src="../imgs/theta_3.png" alt="theta_3"></p><p>接着求解膝关节角度：</p><p>在$\triangle AO_3P$中，由余弦定理有：</p><script type="math/tex; mode=display">cos(\pi-\theta_3) = \frac{l_2^2 + l_3^2 - L^2}{2l_2l_3}</script><p>其中 </p><script type="math/tex; mode=display">L = \sqrt{p_x^2+p_y^2 + p_z^2 - l_1^2}</script><p>因此，</p><script type="math/tex; mode=display">\theta_3 = \pi - arccos(\frac{l_2^2 + l_3^2 - L^2}{2l_2l_3})</script><p>最后求解髋关节角度：</p><p>根据正运动学公式可得：</p><script type="math/tex; mode=display">\frac{p_ysin(\theta_1)-p_zcos(\theta_1)}{p_x} = \frac{l_3sin(\theta_2)sin(\theta_3) - l_3cos(\theta_3+l_2)cos(\theta_2)}{(l_3cos(\theta_3)+l_2)sin(\theta_2) + l_3sin(\theta_3)cos(\theta_2)}</script><p>令：</p><script type="math/tex; mode=display">\begin{align}    a_1 &= p_ysin(\theta_1)-p_zcos(\theta_1) \\    a_2 &= x_p \\    m_1 &= l_3sin(\theta_3) \\    m_2 &= l_3cos(\theta_3) + l_2 \\\end{align}</script><p>则有，</p><script type="math/tex; mode=display">\frac{a_1}{a_2} = \frac{m_1tan(\theta_2) - m_2}{m_1 + m_2tan(\theta_2)}</script><p>最后可解得：</p><script type="math/tex; mode=display">\theta_2 = arctan(\frac{a_1m_1+a_2m_2}{a_2m_1-a_1m_2})</script><h3 id="雅可比矩阵"><a href="#雅可比矩阵" class="headerlink" title="雅可比矩阵"></a>雅可比矩阵</h3><p>末端速度与关节角速度之间的映射关系通过雅可比矩阵来表达，对于四足机器人，雅可比矩阵可以通过对正运动学得到的结果求导得到：</p><script type="math/tex; mode=display">\begin{bmatrix}    \dot{p_x} \\    \dot{p_y} \\    \dot{p_z}\end{bmatrix} = J\begin{bmatrix}    \dot{\theta_1} \\    \dot{\theta_2} \\    \dot{\theta_3}\end{bmatrix}</script><script type="math/tex; mode=display">J = \begin{bmatrix}    0 & -l_2cos(\theta_2)-l_3cos(\theta_2+\theta_3) & -l_3cos(\theta_2+\theta_3) \\    -\epsilon*l_1sin(\theta_1) + l_2cos(\theta_1)cos(\theta_2) + l_3cos(\theta_1)cos(\theta_2+\theta_3) & -l_2sin(\theta_1)sin(\theta_2)-l_3sin(\theta_1)sin(\theta_2+\theta_3) & -l_3sin(\theta_1)sin(\theta_2+\theta_3) \\    \epsilon*l_1cos(\theta_1)+l_2sin(\theta_1)cos(\theta_2)+l_3sin(\theta_1)cos(\theta_2+\theta_3) & l_2cos(\theta_1)sin(\theta_2)+l_3cos(\theta_1)sin(\theta_2+\theta_3) & l_3cos(\theta_1)sin(\theta_2+\theta_3)\end{bmatrix}</script><p>此外，雅可比矩阵还可以做足端力和关节力矩之间的映射：</p><script type="math/tex; mode=display">\tau = J^T F</script><h3 id="逆运动学的数值求解"><a href="#逆运动学的数值求解" class="headerlink" title="逆运动学的数值求解"></a>逆运动学的数值求解</h3><script type="math/tex; mode=display">\Delta q = J^{-1} \Delta x</script><p>基于雅可比矩阵，可以进行逆运动学的数值求解，原理在于通过迭代方法，不断缩小与目标位姿的差距，其算法流程如下：</p><ol><li>初始化关节角度</li><li>根据正运动学求解末端关节位姿</li><li>与目标位姿作差，得到误差值</li><li>根据位姿误差，得到关节角度修正量</li><li>更新关节角度，返回2<br>以上流程在位姿误差小于设定的阈值或到达最大迭代步数时退出。</li></ol><h3 id="程序验证"><a href="#程序验证" class="headerlink" title="程序验证"></a>程序验证</h3><p>参考<a href="https://github.com/great-new-dog/quadruped_control/">quadruped_control仓库</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 足式机器人 </tag>
            
            <tag> 运动学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四足机器运动控制系列————足式机器人概述</title>
      <link href="/post/250434e.html"/>
      <url>/post/250434e.html</url>
      
        <content type="html"><![CDATA[<h3 id="足式机器人定义"><a href="#足式机器人定义" class="headerlink" title="足式机器人定义"></a>足式机器人定义</h3><p>足式机器人是指模仿动物四肢形态和步态而设计的机器人，通常由多个关节组成，具备在复杂地形上自主行走、攀爬、越障等能力。</p><p><img src="/imgs/atlas.jpeg" alt="波士顿动力 Atlas"><br><img src="/imgs/quadrupted_robot.jpeg" alt="宇树 Go2"></p><h3 id="足式机器人发展历程"><a href="#足式机器人发展历程" class="headerlink" title="足式机器人发展历程"></a>足式机器人发展历程</h3><p>足式机器人最早可以追溯到19世纪70年代，当时俄罗斯帝国的机械工程师Chebyshev发明了第一个机械行走机构，被称为“步行机”(Walking Machine)。</p><p>到20世纪40年代，研究人员和工程技术人员开始探索行走机器人的潜在应用。英国的 Hutchinson 和 Smith 按比例建造了一个0.6米高的四足机器人，该机器人有八个运动关节，可用于装甲车的测试。这应该是第一台具有地形适应能力的四足机器人。</p><p>1980年开始，东京工业大学的Hirose开发了泰坦系列四足机器人。到1989年，Kumar 和 Waldron 开发了Raibert机器人，是首个应用动力学控制实现对角、奔跑等步态的四足机器人。</p><p>从21世纪开始，大名鼎鼎的<a href="https://en.wikipedia.org/wiki/Boston_Dynamics">波士顿公司</a>研发了多款足式机器人，如四足机器人”Big Dog”,”Spot Mini”以及双足机器人“Atlas”等。</p><p>近些年来，国内足式机器人行业蓬勃发展，<a href="https://www.unitree.com/cn/">宇树科技</a>、<a href="https://www.deeprobotics.cn/">云深处科技</a>、<a href="https://limxdynamics.com/">逐迹动力</a>、<a href="https://www.robotera.com/">星动纪元</a>、<a href="https://www.zhiyuan-robot.com/">智元机器人</a>等等公司都大放异彩，尤其宇树科技和云深处科技，俨然成为国内四足机器人的两颗双子星，影响力日趋广大。</p><h3 id="足式机器人特点"><a href="#足式机器人特点" class="headerlink" title="足式机器人特点"></a>足式机器人特点</h3><p>足式机器人一般同轮式机器人、履带式机器人一起对比，各自特点如下表格。</p><div class="table-container"><table><thead><tr><th>对比维度</th><th>足式机器人</th><th>轮式机器人</th><th>履带式机器人</th></tr></thead><tbody><tr><td>灵活性</td><td>高灵活性，适应复杂地形</td><td>灵活性较差，适合平坦地形</td><td>灵活性中等，适应多种地形</td></tr><tr><td>动态平衡</td><td>动态平衡能力强</td><td>动态平衡能力弱</td><td>动态平衡能力中等</td></tr><tr><td>环境适应性</td><td>环境适应性强</td><td>适应性较弱</td><td>适应性强</td></tr><tr><td>设计复杂性</td><td>设计复杂</td><td>设计简单</td><td>设计复杂性中等</td></tr><tr><td>能耗</td><td>能耗较高</td><td>能耗低</td><td>能耗中等</td></tr><tr><td>移动速度</td><td>移动速度较慢</td><td>移动速度快</td><td>移动速度中等</td></tr><tr><td>越障能力</td><td>越障能力强</td><td>越障能力弱</td><td>越障能力强</td></tr><tr><td>负载能力</td><td>负载能力弱</td><td>负载能力中等</td><td>负载能力强</td></tr><tr><td>多样性</td><td>设计多样化</td><td>设计单一</td><td>设计单一</td></tr></tbody></table></div><p>通过上述对比，可以发现，足式机器人的优势在于灵活性、环境适应性和越障能力，但是在能耗和移动速度方面相对不足。</p><h3 id="足式机器人运动控制算法"><a href="#足式机器人运动控制算法" class="headerlink" title="足式机器人运动控制算法"></a>足式机器人运动控制算法</h3><p>足式机器人的运动控制算法大致可以分为5个阶段：</p><ul><li>第一阶段：弹簧倒立摆模型 (Hopping 机器人)</li><li>第二阶段：动力学模型 (Spring Flamingo机器人)</li><li>第三阶段：零力矩点法 (本田 P2，P3机器人)</li><li>第四阶段：模型预测+全身控制 (Cheetah mini)</li><li>第五阶段：强化学习/模仿学习 (Anymal)</li></ul><p>当前的足式机器人正朝着智能化控制与仿生学方向发展，控制方法逐渐由传统的基于模型控制方法转向无模型的学习类方法。基于强化学习/模仿学习的方法大大提升了足式机器人的动态运动能力、环境适应能力，大大加速了该行业的发展。</p><h3 id="足式机器人展望"><a href="#足式机器人展望" class="headerlink" title="足式机器人展望"></a>足式机器人展望</h3><p>当然，目前足式机器人的应用范围还有很大的扩展空间，现阶段的足式机器人还主要应用在科研，表演等场景中，在工业领域的落地方案还不是很多。这一现象和足式机器人本身的特点以及当前机器人的性能息息相关，除了解决运动控制本身如稳定性和安全性等问题外，如何近一步降低生产制造成本，优化能耗管理也是急需解决的重点问题。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 足式机器人 </tag>
            
            <tag> 行业发展 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>测试发布文章</title>
      <link href="/post/8c977693.html"/>
      <url>/post/8c977693.html</url>
      
        <content type="html"><![CDATA[<h3 id="基本文字测试"><a href="#基本文字测试" class="headerlink" title="基本文字测试"></a>基本文字测试</h3><p>这是一些没有意义的测试文字。</p><h3 id="图片测试"><a href="#图片测试" class="headerlink" title="图片测试"></a>图片测试</h3><p>这里放一张图片<br><img src="/imgs/bg.jpeg" alt=""></p><h3 id="公式测试"><a href="#公式测试" class="headerlink" title="公式测试"></a>公式测试</h3><p>放一个最美的数学公式：</p><script type="math/tex; mode=display">1 + e^{i\pi} = 0</script><h3 id="程序测试"><a href="#程序测试" class="headerlink" title="程序测试"></a>程序测试</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="type">int</span> main</span><br><span class="line">&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Hello World&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>就先这样吧，看起来还行。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/post/4a17b156.html"/>
      <url>/post/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
